{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:12:55.427993Z",
     "iopub.status.busy": "2021-09-11T19:12:55.427711Z",
     "iopub.status.idle": "2021-09-11T19:12:55.436343Z",
     "shell.execute_reply": "2021-09-11T19:12:55.435635Z",
     "shell.execute_reply.started": "2021-09-11T19:12:55.427963Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "# image\n",
    "from PIL import Image\n",
    "\n",
    "# visu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# folder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Carregando dados de imagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem cinco categorias de flores. As imagens são carregadas em uma matriz numpy como matriz e as categorias associadas são carregadas em uma matriz independente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:13:32.993561Z",
     "iopub.status.busy": "2021-09-11T19:13:32.992921Z",
     "iopub.status.idle": "2021-09-11T19:13:32.998022Z",
     "shell.execute_reply": "2021-09-11T19:13:32.997028Z",
     "shell.execute_reply.started": "2021-09-11T19:13:32.993503Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = [\"dandelion\", \"daisy\", \"sunflower\", \"tulip\", \"rose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Redimensionamos as imagens para que todas tenham a mesma largura e altura. Selecionamos a largura como a largura média de todas as imagens e a altura como a altura média de todas as imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:13:47.830308Z",
     "iopub.status.busy": "2021-09-11T19:13:47.830025Z",
     "iopub.status.idle": "2021-09-11T19:14:32.166385Z",
     "shell.execute_reply": "2021-09-11T19:14:32.165644Z",
     "shell.execute_reply.started": "2021-09-11T19:13:47.830278Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "images_shapes = {\"height\": [], \"width\": []}\n",
    "#\n",
    "for cat in categories:\n",
    "    filelist = glob.glob('./data/' + cat + '/*.jpg')\n",
    "    for fname in filelist:\n",
    "        images_shapes[\"height\"].append(np.array(Image.open(fname)).shape[0])\n",
    "        images_shapes[\"width\"].append(np.array(Image.open(fname)).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:14:32.168369Z",
     "iopub.status.busy": "2021-09-11T19:14:32.168102Z",
     "iopub.status.idle": "2021-09-11T19:14:32.180228Z",
     "shell.execute_reply": "2021-09-11T19:14:32.179351Z",
     "shell.execute_reply.started": "2021-09-11T19:14:32.168334Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\"Average height: \" + str(int(np.mean(images_shapes[\"height\"]))))\n",
    "display(\"Average width: \" + str(int(np.mean(images_shapes[\"width\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devido à limitação de memória no Kaggle, não é possível manter 338 x 253. Vamos dividir a altura e a largura por dois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:16:46.955327Z",
     "iopub.status.busy": "2021-09-11T19:16:46.954756Z",
     "iopub.status.idle": "2021-09-11T19:16:46.958859Z",
     "shell.execute_reply": "2021-09-11T19:16:46.958159Z",
     "shell.execute_reply.started": "2021-09-11T19:16:46.955290Z"
    }
   },
   "outputs": [],
   "source": [
    "im_width = int(338/2)\n",
    "im_height = int(253/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:16:47.842663Z",
     "iopub.status.busy": "2021-09-11T19:16:47.842388Z",
     "iopub.status.idle": "2021-09-11T19:16:47.850104Z",
     "shell.execute_reply": "2021-09-11T19:16:47.849231Z",
     "shell.execute_reply.started": "2021-09-11T19:16:47.842633Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\"Used height: \" + str(im_height))\n",
    "display(\"Used width: \" + str(im_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora as imagens são carregadas e redimensionadas com uma largura de 169 e uma altura de 126 e armazenadas na matriz numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:24:48.677408Z",
     "iopub.status.busy": "2021-09-11T19:24:48.677153Z",
     "iopub.status.idle": "2021-09-11T19:24:48.683281Z",
     "shell.execute_reply": "2021-09-11T19:24:48.682611Z",
     "shell.execute_reply.started": "2021-09-11T19:24:48.677380Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:24:49.713735Z",
     "iopub.status.busy": "2021-09-11T19:24:49.712797Z",
     "iopub.status.idle": "2021-09-11T19:25:06.651898Z",
     "shell.execute_reply": "2021-09-11T19:25:06.650335Z",
     "shell.execute_reply.started": "2021-09-11T19:24:49.713686Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for cat in categories:\n",
    "    filelist = glob.glob('./data/' + cat + '/*.jpg')\n",
    "    target.extend([cat for _ in filelist])\n",
    "    data.extend([np.array(Image.open(fname).resize((im_width, im_height))) for fname in filelist])\n",
    "#\n",
    "data_array = np.stack(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, temos 4317 imagens de tensor de largura 169 e altura 126, cada pixel sendo definido por três cores R, G, B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:25:15.778372Z",
     "iopub.status.busy": "2021-09-11T19:25:15.778092Z",
     "iopub.status.idle": "2021-09-11T19:25:15.783540Z",
     "shell.execute_reply": "2021-09-11T19:25:15.782647Z",
     "shell.execute_reply.started": "2021-09-11T19:25:15.778342Z"
    }
   },
   "outputs": [],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar por imagens aleatórias se cada um deles tem o mesmo tamanho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:20:09.145713Z",
     "iopub.status.busy": "2021-09-11T19:20:09.145407Z",
     "iopub.status.idle": "2021-09-11T19:20:10.084812Z",
     "shell.execute_reply": "2021-09-11T19:20:10.083503Z",
     "shell.execute_reply.started": "2021-09-11T19:20:09.145682Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "gs = fig.add_gridspec(4, 4)\n",
    "#\n",
    "for line in range(0, 3):\n",
    "    for row in range(0, 3):\n",
    "        num_image = random.randint(0, data_array.shape[0])\n",
    "        ax = fig.add_subplot(gs[line, row])\n",
    "        ax.axis('off');\n",
    "        ax.set_title(target[num_image])\n",
    "        ax.imshow(data_array[num_image]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Treinando a divisão do teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conforme indicado nas instruções, usamos a semente aleatória 43 e um tamanho de conjunto de teste de 20% do conjunto de dados. Além disso, usamos o parâmetro `stratify`set to` target` para que a repartição da classe seja mantida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:25:28.161075Z",
     "iopub.status.busy": "2021-09-11T19:25:28.160493Z",
     "iopub.status.idle": "2021-09-11T19:25:28.173578Z",
     "shell.execute_reply": "2021-09-11T19:25:28.172361Z",
     "shell.execute_reply.started": "2021-09-11T19:25:28.161036Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(target).value_counts()/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:27:23.548254Z",
     "iopub.status.busy": "2021-09-11T19:27:23.547989Z",
     "iopub.status.idle": "2021-09-11T19:27:23.643595Z",
     "shell.execute_reply": "2021-09-11T19:27:23.642804Z",
     "shell.execute_reply.started": "2021-09-11T19:27:23.548226Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_array, np.array(target), random_state=43, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:27:30.256938Z",
     "iopub.status.busy": "2021-09-11T19:27:30.256457Z",
     "iopub.status.idle": "2021-09-11T19:27:30.262004Z",
     "shell.execute_reply": "2021-09-11T19:27:30.261286Z",
     "shell.execute_reply.started": "2021-09-11T19:27:30.256894Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:27:46.592752Z",
     "iopub.status.busy": "2021-09-11T19:27:46.592202Z",
     "iopub.status.idle": "2021-09-11T19:27:46.604664Z",
     "shell.execute_reply": "2021-09-11T19:27:46.603727Z",
     "shell.execute_reply.started": "2021-09-11T19:27:46.592717Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:05.330326Z",
     "iopub.status.busy": "2021-09-11T19:28:05.329706Z",
     "iopub.status.idle": "2021-09-11T19:28:05.349274Z",
     "shell.execute_reply": "2021-09-11T19:28:05.348435Z",
     "shell.execute_reply.started": "2021-09-11T19:28:05.330280Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).value_counts()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preparando os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização\n",
    "Para facilitar a convergência do algoritmo, é útil normalizar os dados. Veja aqui quais são os valores máximo e mínimo nos dados e normalize-os de acordo (as intensidades da imagem resultante devem estar entre 0 e 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:28.212500Z",
     "iopub.status.busy": "2021-09-11T19:28:28.212228Z",
     "iopub.status.idle": "2021-09-11T19:28:28.579268Z",
     "shell.execute_reply": "2021-09-11T19:28:28.578377Z",
     "shell.execute_reply.started": "2021-09-11T19:28:28.212471Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:31.904091Z",
     "iopub.status.busy": "2021-09-11T19:28:31.903639Z",
     "iopub.status.idle": "2021-09-11T19:28:34.723557Z",
     "shell.execute_reply": "2021-09-11T19:28:34.722697Z",
     "shell.execute_reply.started": "2021-09-11T19:28:31.904054Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_norm = np.round((X_test/255), 3).copy()\n",
    "X_train_norm = np.round((X_train/255), 3).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, novamente, podemos verificar as imagens normalizadas aleatoriamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:44.255863Z",
     "iopub.status.busy": "2021-09-11T19:28:44.255343Z",
     "iopub.status.idle": "2021-09-11T19:28:45.055303Z",
     "shell.execute_reply": "2021-09-11T19:28:45.054535Z",
     "shell.execute_reply.started": "2021-09-11T19:28:44.255825Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "gs = fig.add_gridspec(4, 4)\n",
    "#\n",
    "for line in range(0, 3):\n",
    "    for row in range(0, 3):\n",
    "        num_image = random.randint(0, X_train_norm.shape[0])\n",
    "        ax = fig.add_subplot(gs[line, row])\n",
    "        ax.axis('off');\n",
    "        ax.set_title(y_train[num_image])\n",
    "        ax.imshow(X_train_norm[num_image]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificação de destino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, convertemos os alvos. Primeiro, de string para valores numéricos, cada categoria se tornando um número inteiro, de 0 a 4 (já que existem cinco categorias de flores diferentes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:07.915200Z",
     "iopub.status.busy": "2021-09-11T19:29:07.914320Z",
     "iopub.status.idle": "2021-09-11T19:29:07.927369Z",
     "shell.execute_reply": "2021-09-11T19:29:07.926442Z",
     "shell.execute_reply.started": "2021-09-11T19:29:07.915162Z"
    }
   },
   "outputs": [],
   "source": [
    "display(np.array(y_train).shape)\n",
    "display(np.unique(y_train))\n",
    "display(np.array(y_test).shape)\n",
    "display(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando o codificador no conjunto de trem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:11.426160Z",
     "iopub.status.busy": "2021-09-11T19:29:11.423455Z",
     "iopub.status.idle": "2021-09-11T19:29:11.433032Z",
     "shell.execute_reply": "2021-09-11T19:29:11.432189Z",
     "shell.execute_reply.started": "2021-09-11T19:29:11.426111Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando no teste e no conjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:15.453252Z",
     "iopub.status.busy": "2021-09-11T19:29:15.452988Z",
     "iopub.status.idle": "2021-09-11T19:29:15.458650Z",
     "shell.execute_reply": "2021-09-11T19:29:15.457818Z",
     "shell.execute_reply.started": "2021-09-11T19:29:15.453222Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_cat = encoder.transform(y_train)\n",
    "y_test_cat = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E agora, convertemos o resultado em um alvo codificado de um ponto para que possam ser usados para treinar uma rede neural de classificação. Usamos `to_categorical` da biblioteca tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:27.141308Z",
     "iopub.status.busy": "2021-09-11T19:29:27.141048Z",
     "iopub.status.idle": "2021-09-11T19:29:27.146043Z",
     "shell.execute_reply": "2021-09-11T19:29:27.145247Z",
     "shell.execute_reply.started": "2021-09-11T19:29:27.141278Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_oh = to_categorical(y_train_cat)\n",
    "y_test_oh = to_categorical(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:28.568755Z",
     "iopub.status.busy": "2021-09-11T19:29:28.568463Z",
     "iopub.status.idle": "2021-09-11T19:29:28.598337Z",
     "shell.execute_reply": "2021-09-11T19:29:28.597493Z",
     "shell.execute_reply.started": "2021-09-11T19:29:28.568726Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test_oh).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolutionnal neural network (Rede neural convolucional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos definir a Rede Neural Convolucional.\n",
    "\n",
    "A CNN que é composta por:\n",
    "- uma camada Conv2D com 32 filtros, um tamanho de kernel de (3, 3), a função de ativação relu, um preenchimento igual a `same` e a `input_shape` correta\n",
    "- uma camada MaxPooling2D com um tamanho de (2, 2)\n",
    "- uma camada Conv2D com 64 filtros, um tamanho de kernel de (3, 3), a função de ativação relu e um preenchimento igual a `same`\n",
    "- uma camada MaxPooling2D com um tamanho de (2, 2)\n",
    "- uma camada Conv2D com 128 filtros, um tamanho de kernel de (3, 3), a função de ativação relu e um preenchimento igual a `same`\n",
    "- uma camada MaxPooling2D com um tamanho de (3, 3)\n",
    "- uma camada achatada\n",
    "- uma função densa com 120 neurônios com a função de ativação `relu`\n",
    "- uma função densa com 60 neurônios com a função de ativação `relu`\n",
    "- uma camada de dropout (com uma taxa de 0,5), para regularizar a rede\n",
    "- uma função densa relacionada à sua tarefa: multiclassificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:30:07.680069Z",
     "iopub.status.busy": "2021-09-11T19:30:07.679806Z",
     "iopub.status.idle": "2021-09-11T19:30:07.689822Z",
     "shell.execute_reply": "2021-09-11T19:30:07.687289Z",
     "shell.execute_reply.started": "2021-09-11T19:30:07.680039Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(im_height, im_width, 3), padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dense(60, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:30:09.747228Z",
     "iopub.status.busy": "2021-09-11T19:30:09.746947Z",
     "iopub.status.idle": "2021-09-11T19:30:09.846782Z",
     "shell.execute_reply": "2021-09-11T19:30:09.846094Z",
     "shell.execute_reply.started": "2021-09-11T19:30:09.747198Z"
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:30:18.985372Z",
     "iopub.status.busy": "2021-09-11T19:30:18.985073Z",
     "iopub.status.idle": "2021-09-11T19:30:18.991617Z",
     "shell.execute_reply": "2021-09-11T19:30:18.989244Z",
     "shell.execute_reply.started": "2021-09-11T19:30:18.985329Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=\"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui é definido uma parada precoce após 5 épocas e defino o parâmetro `restore_best_weights` como` True` para que os pesos da melhor pontuação na métrica monitorada - aqui `val_accuracy` (precisão no conjunto de teste) - sejam restaurados quando o treinamento for interrompido. Dessa forma, o modelo tem a melhor precisão possível em dados não vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:51:55.351712Z",
     "iopub.status.busy": "2021-09-11T19:51:55.351192Z",
     "iopub.status.idle": "2021-09-11T19:52:32.274138Z",
     "shell.execute_reply": "2021-09-11T19:52:32.273440Z",
     "shell.execute_reply.started": "2021-09-11T19:51:55.351666Z"
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model = compile_model(model)\n",
    "es = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n",
    "\n",
    "#model = initialize_model()\n",
    "history = model.fit(X_train_norm, y_train_oh,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test_norm, y_test_oh),\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:52:41.129021Z",
     "iopub.status.busy": "2021-09-11T19:52:41.128422Z",
     "iopub.status.idle": "2021-09-11T19:52:41.517713Z",
     "shell.execute_reply": "2021-09-11T19:52:41.517030Z",
     "shell.execute_reply.started": "2021-09-11T19:52:41.128982Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)\n",
    "\n",
    "plot_history(history, title='', axs=None, exp_name=\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:52:47.192407Z",
     "iopub.status.busy": "2021-09-11T19:52:47.191826Z",
     "iopub.status.idle": "2021-09-11T19:52:47.734448Z",
     "shell.execute_reply": "2021-09-11T19:52:47.733775Z",
     "shell.execute_reply.started": "2021-09-11T19:52:47.192366Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test_norm, y_test_oh, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, temos uma precisão de dados não vistos de quase 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data augmentation (Aumento de dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tentamos melhorar a precisão do modelo usando o aumento de dados. Consiste em aplicar pouca transformação às imagens de entrada sem alterar seu rótulo.\n",
    "\n",
    "Para isso, usamos `ImageDataGenerator` do tensorflow. Ele irá gerar imagens um pouco diferentes de uma imagem original, de modo que será como se o algoritmo estivesse treinando em mais dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             rotation_range=10,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             zoom_range=(0.8, 1.2),) \n",
    "#\n",
    "datagen.fit(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, podemos olhar para a imagem original e a mesma imagem após sua pequena transformação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented = datagen.flow(X_train_norm, shuffle=False, batch_size=1)\n",
    "\n",
    "for i, (raw_image, augmented_image) in enumerate(zip(X_train_norm, X_augmented)):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
    "    ax1.imshow(raw_image)\n",
    "    ax2.imshow(augmented_image[0])\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar o modelo com esta melhoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug = initialize_model()\n",
    "model_aug = compile_model(model_aug)\n",
    "train_flow = datagen.flow(X_train_norm, y_train_oh, batch_size=32)\n",
    "es = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n",
    "\n",
    "#model = initialize_model()\n",
    "history_aug = model_aug.fit(train_flow,\n",
    "                            epochs=50,\n",
    "                            validation_data=(X_test_norm, y_test_oh),\n",
    "                            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history_aug, title='', axs=None, exp_name=\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aug.evaluate(X_test_norm, y_test_oh, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtemos quase 10% mais precisão em dados não vistos em comparação com o modelo inicial!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axs = plot_history(history_aug, exp_name='data_augmentation')\n",
    "plot_history(history ,axs=axs, exp_name='baseline')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
