{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: block; height: 500px; overflow:hidden;position: relative; padding-bottom:50px\">\n",
    "     <img src=\"https://imgur.com/VF9rSJb.jpg\" style=\"position: absolute;top: 0px;border-radius: 20px; \">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:12:55.427993Z",
     "iopub.status.busy": "2021-09-11T19:12:55.427711Z",
     "iopub.status.idle": "2021-09-11T19:12:55.436343Z",
     "shell.execute_reply": "2021-09-11T19:12:55.435635Z",
     "shell.execute_reply.started": "2021-09-11T19:12:55.427963Z"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import random\n",
    "\n",
    "# image\n",
    "from PIL import Image\n",
    "\n",
    "# visu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# folder\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tensorflow\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Loading image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five flower categories. The images are loaded in a numpy array as matrix and associated categories are loaded in an independent array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:13:32.993561Z",
     "iopub.status.busy": "2021-09-11T19:13:32.992921Z",
     "iopub.status.idle": "2021-09-11T19:13:32.998022Z",
     "shell.execute_reply": "2021-09-11T19:13:32.997028Z",
     "shell.execute_reply.started": "2021-09-11T19:13:32.993503Z"
    }
   },
   "outputs": [],
   "source": [
    "categories = [\"dandelion\", \"daisy\", \"sunflower\", \"tulip\", \"rose\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We resize images so they all have the same width and height. We select the width as the mean width of all images and the height as the mean height of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:13:47.830308Z",
     "iopub.status.busy": "2021-09-11T19:13:47.830025Z",
     "iopub.status.idle": "2021-09-11T19:14:32.166385Z",
     "shell.execute_reply": "2021-09-11T19:14:32.165644Z",
     "shell.execute_reply.started": "2021-09-11T19:13:47.830278Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "images_shapes = {\"height\": [], \"width\": []}\n",
    "#\n",
    "for cat in categories:\n",
    "    filelist = glob.glob('./data/' + cat + '/*.jpg')\n",
    "    for fname in filelist:\n",
    "        images_shapes[\"height\"].append(np.array(Image.open(fname)).shape[0])\n",
    "        images_shapes[\"width\"].append(np.array(Image.open(fname)).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:14:32.168369Z",
     "iopub.status.busy": "2021-09-11T19:14:32.168102Z",
     "iopub.status.idle": "2021-09-11T19:14:32.180228Z",
     "shell.execute_reply": "2021-09-11T19:14:32.179351Z",
     "shell.execute_reply.started": "2021-09-11T19:14:32.168334Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\"Average height: \" + str(int(np.mean(images_shapes[\"height\"]))))\n",
    "display(\"Average width: \" + str(int(np.mean(images_shapes[\"width\"]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of memory limitation in Kaggle, keeping 338 x 253 is not possible. Let's divide the height and width by two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:16:46.955327Z",
     "iopub.status.busy": "2021-09-11T19:16:46.954756Z",
     "iopub.status.idle": "2021-09-11T19:16:46.958859Z",
     "shell.execute_reply": "2021-09-11T19:16:46.958159Z",
     "shell.execute_reply.started": "2021-09-11T19:16:46.955290Z"
    }
   },
   "outputs": [],
   "source": [
    "im_width = int(338/2)\n",
    "im_height = int(253/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:16:47.842663Z",
     "iopub.status.busy": "2021-09-11T19:16:47.842388Z",
     "iopub.status.idle": "2021-09-11T19:16:47.850104Z",
     "shell.execute_reply": "2021-09-11T19:16:47.849231Z",
     "shell.execute_reply.started": "2021-09-11T19:16:47.842633Z"
    }
   },
   "outputs": [],
   "source": [
    "display(\"Used height: \" + str(im_height))\n",
    "display(\"Used width: \" + str(im_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now images are loaded and resized with a width of 169, and a height of 126 and stored in the numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:24:48.677408Z",
     "iopub.status.busy": "2021-09-11T19:24:48.677153Z",
     "iopub.status.idle": "2021-09-11T19:24:48.683281Z",
     "shell.execute_reply": "2021-09-11T19:24:48.682611Z",
     "shell.execute_reply.started": "2021-09-11T19:24:48.677380Z"
    }
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "target = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:24:49.713735Z",
     "iopub.status.busy": "2021-09-11T19:24:49.712797Z",
     "iopub.status.idle": "2021-09-11T19:25:06.651898Z",
     "shell.execute_reply": "2021-09-11T19:25:06.650335Z",
     "shell.execute_reply.started": "2021-09-11T19:24:49.713686Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for cat in categories:\n",
    "    filelist = glob.glob('./data/' + cat + '/*.jpg')\n",
    "    target.extend([cat for _ in filelist])\n",
    "    data.extend([np.array(Image.open(fname).resize((im_width, im_height))) for fname in filelist])\n",
    "#\n",
    "data_array = np.stack(data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 4317 tensor images of width 169 and height 126, each pixel being defined by three colors R, G, B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:25:15.778372Z",
     "iopub.status.busy": "2021-09-11T19:25:15.778092Z",
     "iopub.status.idle": "2021-09-11T19:25:15.783540Z",
     "shell.execute_reply": "2021-09-11T19:25:15.782647Z",
     "shell.execute_reply.started": "2021-09-11T19:25:15.778342Z"
    }
   },
   "outputs": [],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check by random images that each of them have the same size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:20:09.145713Z",
     "iopub.status.busy": "2021-09-11T19:20:09.145407Z",
     "iopub.status.idle": "2021-09-11T19:20:10.084812Z",
     "shell.execute_reply": "2021-09-11T19:20:10.083503Z",
     "shell.execute_reply.started": "2021-09-11T19:20:09.145682Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "gs = fig.add_gridspec(4, 4)\n",
    "#\n",
    "for line in range(0, 3):\n",
    "    for row in range(0, 3):\n",
    "        num_image = random.randint(0, data_array.shape[0])\n",
    "        ax = fig.add_subplot(gs[line, row])\n",
    "        ax.axis('off');\n",
    "        ax.set_title(target[num_image])\n",
    "        ax.imshow(data_array[num_image]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated in the instructions, we use the random seed 43 and a test set size of 20% of the dataset. Moreover, we use the parameter `stratify`set to `target` so that the class repartition is maintained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:25:28.161075Z",
     "iopub.status.busy": "2021-09-11T19:25:28.160493Z",
     "iopub.status.idle": "2021-09-11T19:25:28.173578Z",
     "shell.execute_reply": "2021-09-11T19:25:28.172361Z",
     "shell.execute_reply.started": "2021-09-11T19:25:28.161036Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(target).value_counts()/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:27:23.548254Z",
     "iopub.status.busy": "2021-09-11T19:27:23.547989Z",
     "iopub.status.idle": "2021-09-11T19:27:23.643595Z",
     "shell.execute_reply": "2021-09-11T19:27:23.642804Z",
     "shell.execute_reply.started": "2021-09-11T19:27:23.548226Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_array, np.array(target), random_state=43, test_size=0.2, stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:27:30.256938Z",
     "iopub.status.busy": "2021-09-11T19:27:30.256457Z",
     "iopub.status.idle": "2021-09-11T19:27:30.262004Z",
     "shell.execute_reply": "2021-09-11T19:27:30.261286Z",
     "shell.execute_reply.started": "2021-09-11T19:27:30.256894Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:27:46.592752Z",
     "iopub.status.busy": "2021-09-11T19:27:46.592202Z",
     "iopub.status.idle": "2021-09-11T19:27:46.604664Z",
     "shell.execute_reply": "2021-09-11T19:27:46.603727Z",
     "shell.execute_reply.started": "2021-09-11T19:27:46.592717Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_train).value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:05.330326Z",
     "iopub.status.busy": "2021-09-11T19:28:05.329706Z",
     "iopub.status.idle": "2021-09-11T19:28:05.349274Z",
     "shell.execute_reply": "2021-09-11T19:28:05.348435Z",
     "shell.execute_reply.started": "2021-09-11T19:28:05.330280Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test).value_counts()/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "To ease the convergence of the algorithm, it is usefull to normalize the data. See here what are the maximum and minimum values in the data, and normalize it accordingly (the resulting image intensities should be between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:28.212500Z",
     "iopub.status.busy": "2021-09-11T19:28:28.212228Z",
     "iopub.status.idle": "2021-09-11T19:28:28.579268Z",
     "shell.execute_reply": "2021-09-11T19:28:28.578377Z",
     "shell.execute_reply.started": "2021-09-11T19:28:28.212471Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.max())\n",
    "print(X_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:31.904091Z",
     "iopub.status.busy": "2021-09-11T19:28:31.903639Z",
     "iopub.status.idle": "2021-09-11T19:28:34.723557Z",
     "shell.execute_reply": "2021-09-11T19:28:34.722697Z",
     "shell.execute_reply.started": "2021-09-11T19:28:31.904054Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_norm = np.round((X_test/255), 3).copy()\n",
    "X_train_norm = np.round((X_train/255), 3).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here again, we can check the normalised pictures randomly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:28:44.255863Z",
     "iopub.status.busy": "2021-09-11T19:28:44.255343Z",
     "iopub.status.idle": "2021-09-11T19:28:45.055303Z",
     "shell.execute_reply": "2021-09-11T19:28:45.054535Z",
     "shell.execute_reply.started": "2021-09-11T19:28:44.255825Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,15))\n",
    "gs = fig.add_gridspec(4, 4)\n",
    "#\n",
    "for line in range(0, 3):\n",
    "    for row in range(0, 3):\n",
    "        num_image = random.randint(0, X_train_norm.shape[0])\n",
    "        ax = fig.add_subplot(gs[line, row])\n",
    "        ax.axis('off');\n",
    "        ax.set_title(y_train[num_image])\n",
    "        ax.imshow(X_train_norm[num_image]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert targets. First, from string to numerical values, each category becoming an integer, from 0 to 4 (as there are five different flower categories):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:07.915200Z",
     "iopub.status.busy": "2021-09-11T19:29:07.914320Z",
     "iopub.status.idle": "2021-09-11T19:29:07.927369Z",
     "shell.execute_reply": "2021-09-11T19:29:07.926442Z",
     "shell.execute_reply.started": "2021-09-11T19:29:07.915162Z"
    }
   },
   "outputs": [],
   "source": [
    "display(np.array(y_train).shape)\n",
    "display(np.unique(y_train))\n",
    "display(np.array(y_test).shape)\n",
    "display(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the encoder on train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:11.426160Z",
     "iopub.status.busy": "2021-09-11T19:29:11.423455Z",
     "iopub.status.idle": "2021-09-11T19:29:11.433032Z",
     "shell.execute_reply": "2021-09-11T19:29:11.432189Z",
     "shell.execute_reply.started": "2021-09-11T19:29:11.426111Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = LabelEncoder().fit(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying on both train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:15.453252Z",
     "iopub.status.busy": "2021-09-11T19:29:15.452988Z",
     "iopub.status.idle": "2021-09-11T19:29:15.458650Z",
     "shell.execute_reply": "2021-09-11T19:29:15.457818Z",
     "shell.execute_reply.started": "2021-09-11T19:29:15.453222Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_cat = encoder.transform(y_train)\n",
    "y_test_cat = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we convert the result to one-hot encoded target so that they can be used to train a classification neural network. We use `to_categorical` from tensorflow library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:27.141308Z",
     "iopub.status.busy": "2021-09-11T19:29:27.141048Z",
     "iopub.status.idle": "2021-09-11T19:29:27.146043Z",
     "shell.execute_reply": "2021-09-11T19:29:27.145247Z",
     "shell.execute_reply.started": "2021-09-11T19:29:27.141278Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train_oh = to_categorical(y_train_cat)\n",
    "y_test_oh = to_categorical(y_test_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:29:28.568755Z",
     "iopub.status.busy": "2021-09-11T19:29:28.568463Z",
     "iopub.status.idle": "2021-09-11T19:29:28.598337Z",
     "shell.execute_reply": "2021-09-11T19:29:28.597493Z",
     "shell.execute_reply.started": "2021-09-11T19:29:28.568726Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(y_test_oh).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convolutionnal neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define the Convolutional Neural Network. \n",
    "\n",
    "The CNN that is composed of:\n",
    "- a Conv2D layer with 32 filters, a kernel size of (3, 3), the relu activation function, a padding equal to `same` and the correct `input_shape`\n",
    "- a MaxPooling2D layer with a pool size of (2, 2)\n",
    "- a Conv2D layer with 64 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to `same`\n",
    "- a MaxPooling2D layer with a pool size of (2, 2)\n",
    "- a Conv2D layer with 128 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to `same`\n",
    "- a MaxPooling2D layer with a pool size of (3, 3)\n",
    "- a Flatten layer\n",
    "- a dense function with 120 neurons with the `relu` activation function\n",
    "- a dense function with 60 neurons with the `relu` activation function\n",
    "- a dropout layer (with a rate of 0.5), to regularize the network\n",
    "- a dense function related to your task: multiclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:30:07.680069Z",
     "iopub.status.busy": "2021-09-11T19:30:07.679806Z",
     "iopub.status.idle": "2021-09-11T19:30:07.689822Z",
     "shell.execute_reply": "2021-09-11T19:30:07.687289Z",
     "shell.execute_reply.started": "2021-09-11T19:30:07.680039Z"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(im_height, im_width, 3), padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding='same'))\n",
    "    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dense(60, activation='relu'))\n",
    "    model.add(layers.Dropout(rate=0.2))\n",
    "    model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:30:09.747228Z",
     "iopub.status.busy": "2021-09-11T19:30:09.746947Z",
     "iopub.status.idle": "2021-09-11T19:30:09.846782Z",
     "shell.execute_reply": "2021-09-11T19:30:09.846094Z",
     "shell.execute_reply.started": "2021-09-11T19:30:09.747198Z"
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:30:18.985372Z",
     "iopub.status.busy": "2021-09-11T19:30:18.985073Z",
     "iopub.status.idle": "2021-09-11T19:30:18.991617Z",
     "shell.execute_reply": "2021-09-11T19:30:18.989244Z",
     "shell.execute_reply.started": "2021-09-11T19:30:18.985329Z"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=\"accuracy\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I set an early stopping after 5 epochs and set the parameter `restore_best_weights` to `True` so that the weights of best score on monitored metric - here `val_accuracy` (accuracy on test set) - are restored when training stops. This way the model has the best accuracy possible on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:51:55.351712Z",
     "iopub.status.busy": "2021-09-11T19:51:55.351192Z",
     "iopub.status.idle": "2021-09-11T19:52:32.274138Z",
     "shell.execute_reply": "2021-09-11T19:52:32.273440Z",
     "shell.execute_reply.started": "2021-09-11T19:51:55.351666Z"
    }
   },
   "outputs": [],
   "source": [
    "model = initialize_model()\n",
    "model = compile_model(model)\n",
    "es = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n",
    "\n",
    "#model = initialize_model()\n",
    "history = model.fit(X_train_norm, y_train_oh,\n",
    "                    batch_size=16,\n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test_norm, y_test_oh),\n",
    "                    callbacks=[es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:52:41.129021Z",
     "iopub.status.busy": "2021-09-11T19:52:41.128422Z",
     "iopub.status.idle": "2021-09-11T19:52:41.517713Z",
     "shell.execute_reply": "2021-09-11T19:52:41.517030Z",
     "shell.execute_reply.started": "2021-09-11T19:52:41.128982Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label='train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)\n",
    "\n",
    "plot_history(history, title='', axs=None, exp_name=\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:52:47.192407Z",
     "iopub.status.busy": "2021-09-11T19:52:47.191826Z",
     "iopub.status.idle": "2021-09-11T19:52:47.734448Z",
     "shell.execute_reply": "2021-09-11T19:52:47.733775Z",
     "shell.execute_reply.started": "2021-09-11T19:52:47.192366Z"
    }
   },
   "outputs": [],
   "source": [
    "model.evaluate(X_test_norm, y_test_oh, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have an accuracy on unseen data of almost 70%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to improve the model accuracy by using the data augmentation. It consists in applying little transformation to input images without changing its label.\n",
    "\n",
    "For this, we use `ImageDataGenerator` from tensorflow. It will generate images a little bit different from an original image so that it will be like the algorithm is training on more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:31:56.715929Z",
     "iopub.status.busy": "2021-09-11T19:31:56.715411Z",
     "iopub.status.idle": "2021-09-11T19:31:57.386451Z",
     "shell.execute_reply": "2021-09-11T19:31:57.385689Z",
     "shell.execute_reply.started": "2021-09-11T19:31:56.715888Z"
    }
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=False,\n",
    "                             featurewise_std_normalization=False,\n",
    "                             rotation_range=10,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             vertical_flip=True,\n",
    "                             zoom_range=(0.8, 1.2),) \n",
    "#\n",
    "datagen.fit(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here after, we can look at the original image, and the same image after its small transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:32:04.923600Z",
     "iopub.status.busy": "2021-09-11T19:32:04.923300Z",
     "iopub.status.idle": "2021-09-11T19:32:09.043662Z",
     "shell.execute_reply": "2021-09-11T19:32:09.042915Z",
     "shell.execute_reply.started": "2021-09-11T19:32:04.923568Z"
    }
   },
   "outputs": [],
   "source": [
    "X_augmented = datagen.flow(X_train_norm, shuffle=False, batch_size=1)\n",
    "\n",
    "for i, (raw_image, augmented_image) in enumerate(zip(X_train_norm, X_augmented)):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
    "    ax1.imshow(raw_image)\n",
    "    ax2.imshow(augmented_image[0])\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the model with this improvment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:32:42.940087Z",
     "iopub.status.busy": "2021-09-11T19:32:42.939393Z",
     "iopub.status.idle": "2021-09-11T19:42:48.032622Z",
     "shell.execute_reply": "2021-09-11T19:42:48.031816Z",
     "shell.execute_reply.started": "2021-09-11T19:32:42.940049Z"
    }
   },
   "outputs": [],
   "source": [
    "model_aug = initialize_model()\n",
    "model_aug = compile_model(model_aug)\n",
    "train_flow = datagen.flow(X_train_norm, y_train_oh, batch_size=32)\n",
    "es = EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True)\n",
    "\n",
    "#model = initialize_model()\n",
    "history_aug = model_aug.fit(train_flow,\n",
    "                            epochs=50,\n",
    "                            validation_data=(X_test_norm, y_test_oh),\n",
    "                            callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:43:09.519420Z",
     "iopub.status.busy": "2021-09-11T19:43:09.519137Z",
     "iopub.status.idle": "2021-09-11T19:43:09.916746Z",
     "shell.execute_reply": "2021-09-11T19:43:09.915835Z",
     "shell.execute_reply.started": "2021-09-11T19:43:09.519390Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_history(history_aug, title='', axs=None, exp_name=\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T19:43:16.889920Z",
     "iopub.status.busy": "2021-09-11T19:43:16.889646Z",
     "iopub.status.idle": "2021-09-11T19:43:17.331871Z",
     "shell.execute_reply": "2021-09-11T19:43:17.330950Z",
     "shell.execute_reply.started": "2021-09-11T19:43:16.889890Z"
    }
   },
   "outputs": [],
   "source": [
    "model_aug.evaluate(X_test_norm, y_test_oh, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain almost 10% more accuracy on unseen data compared to the initial model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-11T20:00:53.177164Z",
     "iopub.status.busy": "2021-09-11T20:00:53.176902Z",
     "iopub.status.idle": "2021-09-11T20:00:53.967180Z",
     "shell.execute_reply": "2021-09-11T20:00:53.966423Z",
     "shell.execute_reply.started": "2021-09-11T20:00:53.177135Z"
    }
   },
   "outputs": [],
   "source": [
    "axs = plot_history(history_aug, exp_name='data_augmentation')\n",
    "plot_history(history ,axs=axs, exp_name='baseline')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Thank you for reading 🙂</b> <br>if you have any remarks about the content of this notebook, if there are some mistakes or if you have suggestions for improvment, please feel free to comment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
